\\wsl$ в Windows Explorer покажет каталоги Windows Subsystem Linux
C:\Users\sshab\AppData\Local\Docker\wsl\data - здесь живет виртуальный диск (vhdx ( virtual machine disk)) для Докера
docker info - покаызывает параметры докера
you can terminate docker process and open ext4.vhdx file ( with 7zip for example), and there you can see version-pack-data\community\docker 

cr.yandex/crp1r8pht0n0gl25aug1/project-sprint-3:latest - image with working airflow 
its dags are in /lessons/dags
команда SET в терминале запущенного контейнера показывает системные переменные, в т.ч. AIRFLOW_HOME=/opt/airflow
/opt/airflow/airflow.cfg - файл настроек. Содержит все, в т.ч. пути к файлам dags

Настройка среды:
0) инсталлировать Visual Studio Code, Python, GitHub Desktop, Windows Linux Subsystem, Docker Desktop
1) Создать пустой (но с readme) репозиторий в github.com
2) Клонировать репозиторий локально в GitHub Desktop (File -> Clone Repository..)
3) Создать папку dag в папке локального клона репозитория
4) Настроить Visual Studio Code (VSC) на папку локального клона репозитория (File -> Open Folder..)
5) В Visual Studio Code инсталлировать недостающие библиотеки для Airflow (необяз, т.к. не придется запускать локально)
6) Когда dag.py написан, переместить его мышкой в папку с dags запущенного контейнера с airflow

Команда в контекстном меню контейнера open with browser открывает VSC напрямую в контейнере!! Открывает в браузере
Надо замэппить папку с дагами (из git) на контейнер.

Airflow supports subfolders in the dag's folder!!!
Dags should have unique dag_ids. if there are 2 dags in different folders with same id, only dag from upmost folder becomes visible. 
Provide prefix to dag's id. 
Use tags to distinguish, filter and sort dags in the dashboard.

In the terminal you can call airflow cli commands. E.g. airflow config get-value core executor

Airflow version is in the bottom of the dashboard. 2.3.0 - my version.

// **************************
TIME AND TIMEZONES in Airflow

https://crontab.guru/examples.html
CRON maximum resolution is 1 minute
*/10 * * * *        every 10 minutes
0 0 * * 6,0         At 00:00 on Saturday and Sunday.
0 0 * * 1-5         At 00:00 on every day-of-week from Monday through Friday.
0 1 * * *           At 01:00.

Airflow dags start day https://infinitelambda.com/airflow-start-date-execution-date/ 
The reason being, as stated above, that Airflow executes the DAG after start_date + interval (daily)
After changing it is required (?) to run (press Run buton in the dashboard)

https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/timezone.html

// **************************

Порты в докере PortBindings 5432/15432. Первое значение - порт внутри докера. 2-е - порт извне докера. Так настраивается подключение к внутренней Postgre
docker run -d -p 3000:3000 -p 15432:5432 --name=deself2 --volume=C:\Users\sshab\Documents\GitHub\deself\data:/deself_data cr.yandex/crp1r8pht0n0gl25aug1/project-sprint-3:latest 

http://localhost:3000/airflow/home
AirflowAdmin  / airflow_pass

docker run --hostname=dbd848472722 --user=root --env=PATH=/usr/local/nvm/v14.18.1/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin --env=INTERPRETER_NAME=python3 --env=SCRIPT_NAME=__test.py --env=TEMPLATE_FILENAME=template.py --env=NVM_DIR=/usr/local/nvm --env=NODE_VERSION=14.18.1 --env=NODE_PATH=/usr/local/nvm/v14.18.1/lib/node_modules --env=PG_VERSION=13 --env=VSC_VERSION=4.0.1 --env=MB_JETTY_PORT=8998 --env=MB_DB_TYPE=postgres --env=MB_DB_DBNAME=metabase --env=MB_DB_PORT=5432 --env=MB_DB_USER=jovyan --env=MB_DB_PASS=jovyan --env=MB_DB_HOST=localhost --env=CB_SERVER_NAME=CloudBeaver Practicum Server --env=CB_SERVER_URL=http://localhost:3000/ --env=CB_ADMIN_NAME=admin --env=CB_ADMIN_PASSWORD=jovyan --env=LC_ALL=ru_RU.UTF-8 --env=AIRFLOW__CORE__LOAD_EXAMPLES=False --env=AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False --env=AIRFLOW_HOME=/opt/airflow --env=PYTHONPATH=:/lessons/dags 
--volume=C:\Users\sshab\Documents\GitHub\deself\data:/deself_data --volume=/lessons --workdir=/agent -p 3000:3000 --runtime=runc -d cr.yandex/crp1r8pht0n0gl25aug1/sprint-3:latest

// **************************
311ae24539bf09995a843c4f6b7ef6a9df2ad38809cf7141621e1b8f4f993178

docker run --hostname=311ae24539bf --user=root --mac-address=02:42:ac:11:00:02 --volume=C:\Users\sshab\Documents\GitHub\deself\data:/deself_data --volume=/project --workdir=/agent -p 3000:3000 -p 15432:5432 --restart=no --runtime=runc -d cr.yandex/crp1r8pht0n0gl25aug1/project-sprint-3:latest

docker run --hostname=311ae24539bf --user=root --mac-address=02:42:ac:11:00:02 --env=PATH=/usr/local/nvm/v14.18.1/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin --env=INTERPRETER_NAME=python3 --env=SCRIPT_NAME=__test.py --env=TEMPLATE_FILENAME=template.py --env=LC_ALL=ru_RU.UTF-8 --env=AIRFLOW__CORE__LOAD_EXAMPLES=False --env=AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False --env=AIRFLOW_HOME=/opt/airflow  --volume=C:\Users\sshab\Documents\GitHub\deself\data:/deself_data --volume=/project --workdir=/agent -p 3000:3000 -p 15432:5432 --restart=no --runtime=runc -d cr.yandex/crp1r8pht0n0gl25aug1/project-sprint-3:latest

// **************************

Jinja reference
https://airflow.apache.org/docs/apache-airflow/stable/templates-ref.html

// **************************
Логи в папке /lessons/logs, сгруппированы по dag, запуску dag, по task и по попытке task-а

Bash operator examples
https://airflow.apache.org/docs/apache-airflow/stable/_modules/airflow/example_dags/example_sensors.html
https://docs.astronomer.io/learn/what-is-a-sensor

====================
from textwrap import fill
print(fill('qwerty asfgh zxcvhb', width=15))

qwerty asfgh
zxcvhb

==================
Если max_active_runs=1 и установлено ежеминутное запускание и в даге есть сенсор-ожидание, то накопленные за время ожидания процессы не стартуют, пока 
ждущий процесс не выполнится, но как только он выполнится, те, что ожидали, начнут стартовать каждую секунду, если условие выполняется